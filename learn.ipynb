{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from collections import deque \n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import Union\n",
    "from torch import optim\n",
    "from torch import distributions\n",
    "import itertools\n",
    "\n",
    "from pandas.util import hash_pandas_object\n",
    "\n",
    "from sim import Scheduler, Random, Leitner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_to_session(x):\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    timestamps_sorted = np.unique(np.array(x['timestamp']))\n",
    "    timestamps_sorted.sort()\n",
    "    \n",
    "    \n",
    "    result['timestamp'] = timestamps_sorted\n",
    "    result['session'] = list(range(len(timestamps_sorted)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hashed lex id's\n",
      "hashed user id\n",
      "timestamp dones\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "lang_map = {'de' : 0, 'en': 1, 'es': 2, 'fr': 3, 'it': 4, 'pt': 5}\n",
    "\n",
    "if not os.path.exists(\"data/cleaned.csv\"):\n",
    "    df = pd.read_csv(\"data/settles.acl16.learning_traces.13m.csv\")\n",
    "\n",
    "    \n",
    "    print(\"hashed lex id's\")\n",
    "    #Hash lexemes for smaller storage\n",
    "    df['lexeme_id'] = (pd.DataFrame(df['lexeme_id']).apply(hash_pandas_object, axis=0) % 1000000).loc[:, 'lexeme_id']\n",
    "    print('hashed user id')\n",
    "    #Hash user id's for smaller storage\n",
    "    df['user_id'] = (pd.DataFrame(df['user_id']).apply(hash_pandas_object, axis=0) % 5000000).loc[:, 'user_id']\n",
    "    \n",
    "    #Map languages to numbers for smaller storage\n",
    "    df['learning_language'] = df['learning_language'].map(lang_map)\n",
    "    df['ui_language'] = df['ui_language'].map(lang_map)\n",
    "    \n",
    "    \n",
    "    df['lexeme_string'] = df.lexeme_string.map(lambda x: x[0: x.find('<')])\n",
    "    \n",
    "    \n",
    "    df_small = df.loc[:, ['lexeme_id', 'lexeme_string']]\n",
    "    df_small = df_small.drop_duplicates()\n",
    "    df_small.to_csv(\"lexeme_map.csv\", index=False)\n",
    "    \n",
    "    #Drop this column as it's inferred from last two\n",
    "    df = df.drop([\"p_recall\", \"lexeme_string\"], axis=1)\n",
    "    \n",
    "    \n",
    "    for c in df.columns:\n",
    "            if c != 'lexeme_string':\n",
    "                df.loc[:, c] = pd.to_numeric(df[c], downcast='unsigned')\n",
    "    \n",
    "    #This adds the item difficulties of each lexeme\n",
    "    item_difficulties = df.groupby('lexeme_id').apply(lambda x: x['history_correct'].sum() / x['history_seen'].sum())\n",
    "    print('timestamp dones')\n",
    "    #This creates a map of user id and timestamp to which session they are learning in.\n",
    "    print(\"1\")\n",
    "    timestamp_map = df.loc[:, ['user_id', 'timestamp']].groupby(['user_id']).apply(timestamp_to_session)\n",
    "    print(\"2\")\n",
    "    timestamp_map = timestamp_map.reset_index().drop(['level_1'], axis = 1).loc[:, ['timestamp', 'user_id', 'session']]\n",
    "\n",
    "\n",
    "    print(\"3\")\n",
    "    #Get session for each one\n",
    "    df = pd.merge(df, timestamp_map,  how='left', \\\n",
    "                                left_on=['user_id','timestamp'], right_on = ['user_id','timestamp'])\n",
    "    print('4')\n",
    "    #Get difficulty for each one\n",
    "    df = pd.merge(df, pd.DataFrame(item_difficulties),  how='left', \\\n",
    "                                left_on=['lexeme_id'], right_on = ['lexeme_id'])\n",
    "    print(\"5\")\n",
    "    df = df.rename(columns={0: \"difficulty\"})\n",
    "    print('hashing users and lexemes')\n",
    "    #Hash user and lexeme\n",
    "    df['user_lex_hash'] = \\\n",
    "            df.loc[:, ['user_id', 'lexeme_id']].apply(hash_pandas_object, axis=1)\n",
    "    \n",
    "    print('groupby userlex hash')\n",
    "    #Get the minimum timestamp for user lex hashes and merge the tables\n",
    "    min_times_per_user = \\\n",
    "            df.loc[:, ['user_lex_hash', 'timestamp']].groupby('user_lex_hash').min()\n",
    "\n",
    "    df = pd.merge(df, pd.DataFrame(min_times_per_user),  how='left', \\\n",
    "                                left_on=['user_lex_hash'], right_on = ['user_lex_hash'])\n",
    "    \n",
    "    \n",
    "    print('sort by user _lex')\n",
    "    #Sort and take the diff\n",
    "    df.sort_values(by=['user_lex_hash', 'timestamp_x'], inplace=True)\n",
    "    \n",
    "    df_og = df.copy()\n",
    "    \n",
    "    df['sess_diff'] = df['session'].diff()\n",
    "\n",
    "\n",
    "    df = df.loc[df['timestamp_x'] != df['timestamp_y']]\n",
    "\n",
    "\n",
    "    for c in df.columns:\n",
    "            if c != 'lexeme_string':\n",
    "                df.loc[:, c] = pd.to_numeric(df[c], downcast='unsigned')\n",
    "\n",
    "    df.to_csv(\"data/cleaned.csv\", index=False)\n",
    "    \n",
    "else:\n",
    "    df = pd.read_csv(\"data/cleaned.csv\")\n",
    "    for c in df.columns:\n",
    "        if c != 'lexeme_string':\n",
    "            df[c] = pd.to_numeric(df[c], downcast='unsigned')\n",
    "            \n",
    "    lexeme_map = pd.read_csv(\"data/lexeme_map.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have about 5 million english learners, 3 million Spanish 1.9 million French and 1.4 million German learners. Italian and Portugese each have hundreds of thousands. It would be useful to restrict out studies to just the English users so we reduce the dimensionality of our dataset.\n",
    "\n",
    "Interestingly this dataset doesn't contain any Germans learning English so our studies will consist of using the Spanish, French and Italians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = df.groupby('lexeme_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = tbl['timestamp_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = df.groupby('lexeme_id').count()\n",
    "\n",
    "nums = tbl['timestamp_x']\n",
    "\n",
    "idxs = nums < 1000\n",
    "\n",
    "print(sum(idxs))\n",
    "\n",
    "print(sum(nums[idxs]))\n",
    "\n",
    "print(sum(nums[~idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(nums[idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(nums[~idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_traj(student):\n",
    "    get all rows of table\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           76390c1350a8dac31186187e2fe1e178\n",
       "1           7dfd7086f3671685e2cf1c1da72796d7\n",
       "2           35a54c25a2cda8127343f6a82e6f6b7d\n",
       "3           0cf63ffe3dda158bc3dbd55682b355ae\n",
       "4           84920990d78044db53c1b012f5bf9ab5\n",
       "                          ...               \n",
       "12854221    d5efc552aaea3109eb5388aa1ec8673d\n",
       "12854222    a826c47947d68549fa81e19cafa57ba0\n",
       "12854223    5e29d77697d23070a1fb92eb6c90e9b6\n",
       "12854224    cdfecc9247566d40bb964a218c54c783\n",
       "12854225    c52ab45d4e22ee7580041911159e3c0c\n",
       "Name: lexeme_id, Length: 12854226, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 'lexeme_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>delta</th>\n",
       "      <th>user_id</th>\n",
       "      <th>learning_language</th>\n",
       "      <th>ui_language</th>\n",
       "      <th>lexeme_id</th>\n",
       "      <th>lexeme_string</th>\n",
       "      <th>history_seen</th>\n",
       "      <th>history_correct</th>\n",
       "      <th>session_seen</th>\n",
       "      <th>session_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>76390c1350a8dac31186187e2fe1e178</td>\n",
       "      <td>lernt/lernen&lt;vblex&gt;&lt;pri&gt;&lt;p3&gt;&lt;sg&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>7dfd7086f3671685e2cf1c1da72796d7</td>\n",
       "      <td>die/die&lt;det&gt;&lt;def&gt;&lt;f&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>35a54c25a2cda8127343f6a82e6f6b7d</td>\n",
       "      <td>mann/mann&lt;n&gt;&lt;m&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>0cf63ffe3dda158bc3dbd55682b355ae</td>\n",
       "      <td>frau/frau&lt;n&gt;&lt;f&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>84920990d78044db53c1b012f5bf9ab5</td>\n",
       "      <td>das/das&lt;det&gt;&lt;def&gt;&lt;nt&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_recall   timestamp     delta user_id learning_language ui_language  \\\n",
       "0       1.0  1362076081  27649635    u:FO                de          en   \n",
       "1       0.5  1362076081  27649635    u:FO                de          en   \n",
       "2       1.0  1362076081  27649635    u:FO                de          en   \n",
       "3       0.5  1362076081  27649635    u:FO                de          en   \n",
       "4       1.0  1362076081  27649635    u:FO                de          en   \n",
       "\n",
       "                          lexeme_id                     lexeme_string  \\\n",
       "0  76390c1350a8dac31186187e2fe1e178  lernt/lernen<vblex><pri><p3><sg>   \n",
       "1  7dfd7086f3671685e2cf1c1da72796d7     die/die<det><def><f><sg><nom>   \n",
       "2  35a54c25a2cda8127343f6a82e6f6b7d          mann/mann<n><m><sg><nom>   \n",
       "3  0cf63ffe3dda158bc3dbd55682b355ae          frau/frau<n><f><sg><nom>   \n",
       "4  84920990d78044db53c1b012f5bf9ab5    das/das<det><def><nt><sg><nom>   \n",
       "\n",
       "   history_seen  history_correct  session_seen  session_correct  \n",
       "0             6                4             2                2  \n",
       "1             4                4             2                1  \n",
       "2             5                4             1                1  \n",
       "3             6                5             2                1  \n",
       "4             4                4             1                1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexeme_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854221</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854222</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854223</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854224</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854225</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12854226 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lexeme_id\n",
       "0                 4\n",
       "1                 8\n",
       "2                 1\n",
       "3                 2\n",
       "4                 3\n",
       "...             ...\n",
       "12854221          4\n",
       "12854222          7\n",
       "12854223          2\n",
       "12854224          0\n",
       "12854225          9\n",
       "\n",
       "[12854226 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.loc[:, 'lexeme_id']).apply(hash_pandas_object) % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
