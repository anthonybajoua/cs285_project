{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from collections import deque \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_map = {'de' : 0, 'en': 1, 'es': 2, 'fr': 3, 'it': 4, 'pt': 5}\n",
    "\n",
    "if not os.path.exists(\"data/cleaned.csv\"):\n",
    "    df = pd.read_csv(\"data/settles.acl16.learning_traces.13m.csv\")\n",
    "\n",
    "    df.sort_values(by=['user_id', 'lexeme_id', 'timestamp'], inplace=True)\n",
    "    \n",
    "    #Drop this column as it's inferred from last two\n",
    "    df = df.drop([\"p_recall\"], axis=1)\n",
    "\n",
    "    #Hash lexemes for smaller storage\n",
    "    df['lexeme_id'] = df['lexeme_id'].apply(hash) % 1000000\n",
    "    \n",
    "    #Hash user id's for smaller storage\n",
    "    df['user_id'] = df['user_id'].apply(hash) % 5000000\n",
    "    \n",
    "    #Map languages to numbers for smaller storage\n",
    "    df['learning_language'] = df['learning_language'].map(lang_map)\n",
    "    df['ui_language'] = df['ui_language'].map(lang_map)\n",
    "    \n",
    "    for c in df.columns:\n",
    "        if c != 'lexeme_string':\n",
    "            df[c] = pd.to_numeric(df[c], downcast='unsigned')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df['lexeme_string'] = df.lexeme_string.map(lambda x: x[0: x.find('<')])\n",
    "    df.to_csv(\"data/cleaned.csv\", index=False)\n",
    "else:\n",
    "    df = pd.read_csv(\"data/cleaned.csv\")\n",
    "    for c in df.columns:\n",
    "        if c != 'lexeme_string':\n",
    "            df[c] = pd.to_numeric(df[c], downcast='unsigned')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If data already cleaned run me instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduling Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scheduler:\n",
    "    \"\"\"\n",
    "    Parent class of any learning scheduler method.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_items):\n",
    "        pass\n",
    "    \n",
    "    def next_item(self):\n",
    "        pass\n",
    "    \n",
    "    def update(self, item, outcome):\n",
    "        pass\n",
    "    \n",
    "\n",
    "class Random(Scheduler):\n",
    "    \"\"\"\n",
    "    Scheduler that selects random items to present.\n",
    "    \"\"\"\n",
    "    def __init(self, num_items):\n",
    "        self.n = num_items\n",
    "    \n",
    "    def next_item(self):\n",
    "        return np.random.randint(0, num_items)\n",
    "    \n",
    "    def update(self, item, outcome):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "\n",
    "class Leitner(Scheduler): \n",
    "    \"\"\"\n",
    "    This class implements a Leitner scheduler that samples from \n",
    "    boxes with exponentially decreasing probability. Cards enter\n",
    "    in box 0 and leave when they are correctly answered after entering \n",
    "    the final box\n",
    "    \"\"\"\n",
    "    def __init__(self, nb):\n",
    "        '''\n",
    "        :param nb: Number of boxes\n",
    "        boxes is a list of queues representing the boxes.\n",
    "        dist_boxes is sampling distribution for which box to select fromr\n",
    "        cards is a set of items in the boxes currently.\n",
    "        '''\n",
    "        self.boxes = [deque() for _ in nb]\n",
    "        self.dist_boxes = np.array([1/2**i for i in range(nb)]) / sum([1/2**i for i in range(nb)])\n",
    "        self.cards = set()\n",
    "        \n",
    "    \n",
    "    def next_item(self):\n",
    "        \"\"\"\n",
    "        Gets the next item in the learning sequence.\n",
    "        \"\"\"\n",
    "        self.recent_box = np.random.multinomial(1, self.dist_boxes).argmax()\n",
    "        \n",
    "        if len(self.boxes[self.recent_box]):\n",
    "            return self.boxes[self.recent_box].pop()\n",
    "        else:\n",
    "            return self.next_item()\n",
    "    \n",
    "    def update(self, item, outcome, thresh=.9):\n",
    "        \"\"\"\n",
    "        Updates the most recent item from the sequence\n",
    "        by putting it back depending on the outcome.\n",
    "        \"\"\"\n",
    "        if outcome > thresh:\n",
    "            new_box = self.recent_box + 1\n",
    "            if new_box >= len(self.boxes):\n",
    "                self.cards.remove(item)\n",
    "            else:\n",
    "                self.boxes[new_box].appendleft(item)\n",
    "        else:\n",
    "            new_box = max(self.recent_box - 1, 0)\n",
    "            \n",
    "            self.boxes[new_box].appendleft(item)\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample trajectories from historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12854226, 11)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleEnv():\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        # State: row corresponds to lexeme id, first column is history_seen, second column is history_correct\n",
    "        self.state = np.zeros((1000000, 2))\n",
    "        self.users = df['user_id'].unique()\n",
    "        \n",
    "    def sample_trajectory(self):\n",
    "        user = self.users[np.random.choice(len(self.users))]\n",
    "        points = self.df[self.df['user_id'] == user]\n",
    "        \n",
    "        obs, actions = [], []\n",
    "        idx = 0\n",
    "        point = points.iloc[idx]\n",
    "        while point['user_id'] == user and idx < points.shape[0]-1:\n",
    "            lex = points['lexeme_id']\n",
    "            self.state[lex][0] = point['history_seen']\n",
    "            self.state[lex][1] = point['history_correct']\n",
    "            obs.append(self.state.copy())\n",
    "            actions.append(points.iloc[idx+1]['lexeme_id'])\n",
    "            idx += 1\n",
    "            point = points.iloc[idx]\n",
    "        return obs, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
