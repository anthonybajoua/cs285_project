{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools, os, torch\n",
    "\n",
    "from sim import Scheduler, Random, Leitner\n",
    "from data_process import process_original, reduce_df, eval_thresh, reduce_lexemes\n",
    "from get_trajectory import get_traj\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data && ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data (clean if necesarry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/cleaned.csv\"):\n",
    "    process_original()\n",
    "    \n",
    "\n",
    "df = pd.read_csv(\"data/cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learning_language\n",
       "0    1452597\n",
       "1    5014791\n",
       "2    3407689\n",
       "3    1873734\n",
       "4     793935\n",
       "5     311480\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_map = {'de' : 0, 'en': 1, 'es': 2, 'fr': 3, 'it': 4, 'pt': 5}\n",
    "l_map = pd.read_csv(\"data/lexeme_map.csv\")\n",
    "\n",
    "df.groupby('learning_language').count().loc[:, 'user_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have about 5 million english items, 3 million Spanish 1.9 million French and 1.4 million German. Italian and Portugese each have hundreds of thousands. It would be useful to restrict out studies to just the English users so we reduce the dimensionality of our action and state spaces.\n",
    "\n",
    "There are 43.8 thousand learners (trajectories) we have to provide our RL agents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['learning_language'] == 1].copy()\n",
    "df = df.drop(['learning_language'], axis=1)\n",
    "reduce_df(df)\n",
    "df.loc[:, 'difficulty'] = df.loc[:, 'difficulty'].astype(np.float32)\n",
    "df.loc[:, 'difficulty'] -= df.loc[:, 'difficulty'].mean()\n",
    "df.loc[:, 'difficulty'] /= df.loc[:, 'difficulty'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2983 lexemes\n"
     ]
    }
   ],
   "source": [
    "english_counts = df.groupby('lexeme_id').count().loc[:, 'timestamp']\n",
    "n_lex = len(english_counts)\n",
    "print(f\"There are {n_lex} lexemes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For threshold 1000 there are 15.32% lexemes above and 84.68% below\n",
      "\n",
      "There would be 90.48% of data included and 9.52% of data excluded\n"
     ]
    }
   ],
   "source": [
    "n_items = int(1000)\n",
    "\n",
    "eval_thresh(df, english_counts, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, included = reduce_lexemes(df, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions, itl, lti = get_traj(df, included)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Behavioral Cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import random\n",
    "import cs285.infrastructure.pytorch_util as ptu\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b7c722a77468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraj_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msample_traj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfirst_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstates_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mactions_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'states' is not defined"
     ]
    }
   ],
   "source": [
    "traj_idxs = list(states.keys())\n",
    "def sample_traj(states, actions, idxs):\n",
    "    first_idx = idxs.pop()\n",
    "    states_cat = states[first_idx]\n",
    "    actions_cat = actions[first_idx]\n",
    "    while states_cat.shape[0] < batch_size and len(idxs) > 0:\n",
    "        new_idx = idxs.pop()\n",
    "        states_cat = np.concatenate((states_cat, states[new_idx]))\n",
    "        actions_cat = np.concatenate((actions_cat, actions[new_idx]))\n",
    "    return states_cat, actions_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
