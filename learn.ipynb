{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools, os, torch\n",
    "\n",
    "from sim import Scheduler, Random, Leitner\n",
    "from data_process import process_original, reduce_df\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data (clean if necesarry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/cleaned.csv\"):\n",
    "    process_original()\n",
    "    \n",
    "\n",
    "df = pd.read_csv(\"data/cleaned.csv\")\n",
    "reduce_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learning_language\n",
       "0    1452597\n",
       "1    5014791\n",
       "2    3407689\n",
       "3    1873734\n",
       "4     793935\n",
       "5     311480\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_map = {'de' : 0, 'en': 1, 'es': 2, 'fr': 3, 'it': 4, 'pt': 5}\n",
    "l_map = pd.read_csv(\"data/lexeme_map.csv\")\n",
    "\n",
    "df.groupby('learning_language').count().loc[:, 'user_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have about 5 million english items, 3 million Spanish 1.9 million French and 1.4 million German. Italian and Portugese each have hundreds of thousands. It would be useful to restrict out studies to just the English users so we reduce the dimensionality of our action and state spaces.\n",
    "\n",
    "There are 43.8 thousand learners (trajectories) we have to provide our RL agents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = df.loc[df['learning_language'] == 1].copy()\n",
    "df_en = df_en.drop(['learning_language'], axis=1)\n",
    "reduce_df(df_en)\n",
    "df_en.loc[:, 'difficulty'] = df_en.loc[:, 'difficulty'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2983 lexemes\n"
     ]
    }
   ],
   "source": [
    "english_counts = df_en.groupby('lexeme_id').count().loc[:, 'timestamp']\n",
    "n_lex = len(english_counts)\n",
    "print(f\"There are {n_lex} lexemes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_thresh(df, counts, thresh):\n",
    "    above, below = sum(counts >= thresh), sum(counts  < thresh)\n",
    "    total = above + below\n",
    "    \n",
    "    excl = sum(counts[counts < thresh])\n",
    "    incl = sum(counts[counts >= thresh])\n",
    "    total2 = incl + excl\n",
    "    \n",
    "    print(f\"For threshold {thresh} there are {100 * above/total:.2f}% lexemes above and {100 * below/total:.2f}% below\\n\")\n",
    "    print(f\"There would be {100 * incl/total2:.2f}% of data included and {100 * excl/total2:.2f}% of data excluded\")\n",
    "    \n",
    "def reduce_lexemes(df, amt):\n",
    "    \"\"\"\n",
    "    Removes all rows of lexemes that appear less than a certain amount.\n",
    "    \"\"\"\n",
    "    cnts = df.groupby('lexeme_id').count().loc[:, 'timestamp']\n",
    "    cnts_incl = cnts >= amt\n",
    "    cnts_incl = cnts_incl.index[cnts_incl]\n",
    "    cnts_incl = set(cnts_incl)\n",
    "    df = df[df.lexeme_id.isin(cnts_incl)]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For threshold 5000.0 there are 6.50% lexemes above and 93.50% below\n",
      "\n",
      "There would be 78.40% of data included and 21.60% of data excluded\n"
     ]
    }
   ],
   "source": [
    "eval_thresh(df_en, english_counts, 5e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_reduced = reduce_lexemes(df_en, 5e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5014791, 3931462)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
