{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "2rsWAWaK9BVp"
   },
   "outputs": [],
   "source": [
    "#@title test virtual display\n",
    "\n",
    "#@markdown If you see a video of a four-legged ant fumbling about, setup is complete!\n",
    "\n",
    "import gym\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QizpiHDh9Fwk"
   },
   "source": [
    "## Editing Code\n",
    "\n",
    "To edit code, click the folder icon on the left menu. Navigate to the corresponding file (`cs285_f2020/...`). Double click a file to open an editor. There is a timeout of about ~12 hours with Colab while it is active (and less if you close your browser window). We sync your edits to Google Drive so that you won't lose your work in the event of an instance timeout, but you will need to re-mount your Google Drive and re-install packages with every new instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nii6qk2C9Ipk"
   },
   "source": [
    "## Run DQN and Double DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.remove(\"/Users/anthony/homework_fall2020/hw2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "4t7FUeEG9Dkf"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cs285.agents.dqn_agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7ffbb6f96693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcs285\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfrastructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_trainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRL_Trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcs285\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcs285\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfrastructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_env_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# import cs285.agents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cs285.agents.dqn_agent'"
     ]
    }
   ],
   "source": [
    "#@title imports\n",
    "import os\n",
    "import time\n",
    "\n",
    "from cs285.infrastructure.rl_trainer import RL_Trainer\n",
    "from cs285.agents.dqn_agent import DQNAgent\n",
    "from cs285.infrastructure.dqn_utils import get_env_kwargs\n",
    "# import cs285.agents\n",
    "# import cs285.infrastructure.utils\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_results.py            run_hw3_dqn.ipynb\n",
      "run_hw3_actor_critic.ipynb run_hw3_dqn.py\n",
      "run_hw3_actor_critic.py\n",
      "read_results.py            run_hw3_dqn.ipynb\n",
      "run_hw3_actor_critic.ipynb run_hw3_dqn.py\n",
      "run_hw3_actor_critic.py\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "2fXlzARJ9i-t"
   },
   "outputs": [],
   "source": [
    "#@title runtime arguments\n",
    "\n",
    "class Args:\n",
    "\n",
    "  def __getitem__(self, key):\n",
    "    return getattr(self, key)\n",
    "\n",
    "  def __setitem__(self, key, val):\n",
    "    setattr(self, key, val)\n",
    "\n",
    "  def __contains__(self, key):\n",
    "    return hasattr(self, key)\n",
    "\n",
    "  env_name = 'MsPacman-v0' #@param ['MsPacman-v0', 'LunarLander-v3', 'PongNoFrameSkip-v4']\n",
    "  exp_name = 'q3_dqn' #@param\n",
    "\n",
    "  ## PDF will tell you how to set ep_len\n",
    "  ## and discount for each environment\n",
    "  ep_len = 200 #@param {type: \"integer\"}\n",
    "\n",
    "  #@markdown batches and steps\n",
    "  batch_size = 32 #@param {type: \"integer\"}\n",
    "  eval_batch_size = 1000 #@param {type: \"integer\"}\n",
    "\n",
    "  num_agent_train_steps_per_iter = 1 #@param {type: \"integer\"}\n",
    "\n",
    "  num_critic_updates_per_agent_update = 1 #@param {type: \"integer\"}\n",
    "  \n",
    "  #@markdown Q-learning parameters\n",
    "  double_q = False #@param {type: \"boolean\"}\n",
    "\n",
    "  #@markdown system\n",
    "  save_params = False #@param {type: \"boolean\"}\n",
    "  no_gpu = False #@param {type: \"boolean\"}\n",
    "  which_gpu = 0 #@param {type: \"integer\"}\n",
    "  seed = 1 #@param {type: \"integer\"}\n",
    "\n",
    "  #@markdown logging\n",
    "  ## default is to not log video so\n",
    "  ## that logs are small enough to be\n",
    "  ## uploaded to gradscope\n",
    "  video_log_freq =  -1 #@param {type: \"integer\"}\n",
    "  scalar_log_freq =  10000#@param {type: \"integer\"}\n",
    "\n",
    "\n",
    "args = Args()\n",
    "\n",
    "## ensure compatibility with hw1 code\n",
    "args['train_batch_size'] = args['batch_size']\n",
    "\n",
    "if args['video_log_freq'] > 0:\n",
    "  import warnings\n",
    "  warnings.warn(\n",
    "      '''\\nLogging videos will make eventfiles too'''\n",
    "      '''\\nlarge for the autograder. Set video_log_freq = -1'''\n",
    "      '''\\nfor the runs you intend to submit.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0cJlp6s-ogO"
   },
   "outputs": [],
   "source": [
    "#@title create directories for logging\n",
    "\n",
    "data_path = '''/content/cs285_f2020/''' \\\n",
    "        '''homework_fall2020/hw3/data'''\n",
    "\n",
    "if not (os.path.exists(data_path)):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "logdir = 'hw3_' + args.exp_name + '_' + args.env_name + '_' + time.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "logdir = os.path.join(data_path, logdir)\n",
    "args['logdir'] = logdir\n",
    "if not(os.path.exists(logdir)):\n",
    "    os.makedirs(logdir)\n",
    "\n",
    "print(\"LOGGING TO: \", logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I525KFRN-42s"
   },
   "outputs": [],
   "source": [
    "#@title Define Q-function trainer\n",
    "\n",
    "class Q_Trainer(object):\n",
    "\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "\n",
    "        train_args = {\n",
    "            'num_agent_train_steps_per_iter': params['num_agent_train_steps_per_iter'],\n",
    "            'num_critic_updates_per_agent_update': params['num_critic_updates_per_agent_update'],\n",
    "            'train_batch_size': params['batch_size'],\n",
    "            'double_q': params['double_q'],\n",
    "        }\n",
    "\n",
    "        env_args = get_env_kwargs(params['env_name'])\n",
    "\n",
    "        for k, v in env_args.items():\n",
    "          params[k] = v\n",
    "\n",
    "        self.params['agent_class'] = DQNAgent\n",
    "        self.params['agent_params'] = params\n",
    "        self.params['train_batch_size'] = params['batch_size']\n",
    "        self.params['env_wrappers'] = env_args['env_wrappers']\n",
    "\n",
    "        self.rl_trainer = RL_Trainer(self.params)\n",
    "\n",
    "    def run_training_loop(self):\n",
    "        self.rl_trainer.run_training_loop(\n",
    "            self.params['num_timesteps'],\n",
    "            collect_policy = self.rl_trainer.agent.actor,\n",
    "            eval_policy = self.rl_trainer.agent.actor,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wF4LSRGn-_Cv"
   },
   "outputs": [],
   "source": [
    "#@title run training\n",
    "\n",
    "trainer = Q_Trainer(args)\n",
    "trainer.run_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kTH-tXkI-B-"
   },
   "outputs": [],
   "source": [
    "#@markdown You can visualize your runs with tensorboard from within the notebook\n",
    "\n",
    "## requires tensorflow==2.3.0\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/cs285_f2020/homework_fall2020/hw3/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"run_hw3_dqn.py\", line 4, in <module>\r\n",
      "    from cs285.infrastructure.rl_trainer import RL_Trainer\r\n",
      "ModuleNotFoundError: No module named 'cs285'\r\n"
     ]
    }
   ],
   "source": [
    "!python run_hw3_dqn.py --env_name LunarLander-v3 --exp_name q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36magents\u001b[m\u001b[m         \u001b[1m\u001b[36menvs\u001b[m\u001b[m           \u001b[1m\u001b[36mpolicies\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mcritics\u001b[m\u001b[m        \u001b[1m\u001b[36minfrastructure\u001b[m\u001b[m \u001b[1m\u001b[36mscripts\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "run_hw3_dqn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
